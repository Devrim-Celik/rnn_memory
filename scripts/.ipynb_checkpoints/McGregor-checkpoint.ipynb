{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class DefaultConfig:\n",
    "    num_epochs = 200 # should be 100.000 steps \n",
    "    batchsize = 128\n",
    "    layer_dim = 50\n",
    "    learning_rate = 1e-4\n",
    "    max_grad_norm = 5.0\n",
    "    fw_lambda = 0.9\n",
    "    fw_eta = 0.5\n",
    "    c_alpha = 40\n",
    "    c_lambda = 0.01\n",
    "    c_layer_norm = True\n",
    "    init_scale = 0.1\n",
    "    layer_norm = True\n",
    "    norm_gain =  1\n",
    "    norm_shift = 1\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    fw_activation = tf.nn.tanh\n",
    "    clip_gradients = False\n",
    "    \n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Don't give me that look, I could not not do this.\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([str(key)+\": \"+str(value) for key, value in DefaultConfig.__dict__.items() if not key.startswith('__') and not callable(key)])\n",
    "    \n",
    "    \n",
    "class Default_AR_Config(DefaultConfig):\n",
    "    anderes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs: 200\n",
      "batchsize: 128\n",
      "layer_dim: 50\n",
      "learning_rate: 0.0001\n",
      "max_grad_norm: 5.0\n",
      "fw_lambda: 0.9\n",
      "fw_eta: 0.5\n",
      "c_alpha: 40\n",
      "c_lambda: 0.01\n",
      "c_layer_norm: True\n",
      "init_scale: 0.1\n",
      "layer_norm: True\n",
      "norm_gain: 1\n",
      "norm_shift: 1\n",
      "optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x120270be0>\n",
      "fw_activation: <function tanh at 0x11a3031e0>\n",
      "clip_gradients: False\n"
     ]
    }
   ],
   "source": [
    "conf = Default_AR_Config()\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9. 9. 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "test = tf.constant(np.ones([5])*9)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res=sess.run(test)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9]],\n",
      "\n",
      "       [[12, 13, 14],\n",
      "        [15, 16, 17],\n",
      "        [18, 19, 20]]], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.util import nest\n",
    "inputs = tf.constant([[[1,2,3],[4,5,6],[7,8,9]],[[12,13,14,],[15,16,17],[18,19,20]]])\n",
    "flat_input = nest.flatten(inputs)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(flat_input)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[4.5,  6.5], [1.2, 7.1]])\n",
    "y = tf.constant([[4.5,  6.5], [1.2, 7.4]])\n",
    "res = tf.reduce_all(tf.equal(x,y))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    erg = sess.run(res)\n",
    "    print(erg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.41421356 1.41421356 1.41421356]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch = tf.constant(np.ones((3,2)))\n",
    "\n",
    "normalized = batch / tf.norm(batch,keepdims=True,axis=1)\n",
    "lengths = tf.norm(batch,keepdims=False,axis=1)\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(lengths)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 4)\n",
      "[[[24. 24. 24. 24.]]\n",
      "\n",
      " [[24. 24. 24. 24.]]\n",
      "\n",
      " [[24. 24. 24. 24.]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "batchsize = 3\n",
    "c = tf.constant(np.ones((batchsize,4,4))*2)\n",
    "state = tf.constant(np.ones((batchsize,1,4))*3)\n",
    "\n",
    "res = tf.matmul(state, c)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(res)\n",
    "    print(result.shape)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "images = map(Image.open, ['heatmap_autoconceptor_mnist28_1.png', 'heatmap_autoconceptor_mnist28_2.png'])\n",
    "widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "total_width = sum(widths)\n",
    "max_height = max(heights)\n",
    "\n",
    "new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "x_offset = 0\n",
    "for im in images:\n",
    "    new_im.paste(im, (x_offset,0))\n",
    "    x_offset += im.size[0]\n",
    "\n",
    "new_im.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_2:0\", shape=(5, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "test = tf.constant(np.ones([5,10,100])) #batchsize x sequence_length x output_dim\n",
    "ma = tf.argmax(test,axis=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(ma)\n",
    "    print(ma) # gewollt: batchsize x sequence_length, also 5x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 0 1 2 3 2 3 4 5 3 4 5 6 5 6 7 8 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "def construct_smart_sequence(data, sequence_length, batchsize):\n",
    "    \"\"\"\n",
    "    data = list of strings (the encoded words of the file)\n",
    "    batchsize = the size of the expected batches\n",
    "    \"\"\"\n",
    "    length = len(data)\n",
    "    chunk = batchsize * sequence_length\n",
    "    rep = int((length - (length % chunk))/chunk)\n",
    "    \n",
    "    indices_pre = np.repeat(np.arange(batchsize)*rep, rep) + np.repeat(np.arange(rep), batchsize)\n",
    "    \n",
    "    indices = np.repeat(indices_pre, sequence_length) + np.tile(np.arange(sequence_length), batchsize*rep)\n",
    "\n",
    "    new_data = data[[indices]]\n",
    "    return new_data\n",
    "\n",
    "print(construct_smart_sequence(np.arange(25),4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_sequence_iter(data, sequence_length, batchsize):\n",
    "    length = len(data)\n",
    "    chunk = batchsize * sequence_length\n",
    "    clean_length = length - (length % chunk)\n",
    "    new_data = []\n",
    "    for s in sequence_starts:\n",
    "        new_data.append(data[s:s+sequence_length])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-735f239ef392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_sequence_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew_data_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-f88bfcb43d59>\u001b[0m in \u001b[0;36mconstruct_sequence_iter\u001b[0;34m(data, sequence_length, batchsize)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_sequence_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclean_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence_starts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunk' is not defined"
     ]
    }
   ],
   "source": [
    "data = list(np.arange(0,24))\n",
    "new_data = construct_sequence_iter(data, 4, 3)\n",
    "new_data_correct = [0,1,2,3,8,9,10,11,16,17,18,19,4,5,6,7,12,13,14,15,20,21,22,23]\n",
    "print(new_data_correct)\n",
    "print(new_data)\n",
    "#assert new_data == new_data_correct,\"Assert failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
