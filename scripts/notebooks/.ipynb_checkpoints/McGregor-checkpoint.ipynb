{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests \n",
    "Tor trying out whether things work the way I think they do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class DefaultConfig:\n",
    "    num_epochs = 200 # should be 100.000 steps \n",
    "    batchsize = 128\n",
    "    layer_dim = 50\n",
    "    learning_rate = 1e-4\n",
    "    max_grad_norm = 5.0\n",
    "    fw_lambda = 0.9\n",
    "    fw_eta = 0.5\n",
    "    c_alpha = 40\n",
    "    c_lambda = 0.01\n",
    "    c_layer_norm = True\n",
    "    init_scale = 0.1\n",
    "    layer_norm = True\n",
    "    norm_gain =  1\n",
    "    norm_shift = 1\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    fw_activation = tf.nn.tanh\n",
    "    clip_gradients = False\n",
    "    \n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Don't give me that look, I could not not do this.\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([str(key)+\": \"+str(value) for key, value in DefaultConfig.__dict__.items() if not key.startswith('__') and not callable(key)])\n",
    "    \n",
    "    \n",
    "class Default_AR_Config(DefaultConfig):\n",
    "    anderes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs: 200\n",
      "batchsize: 128\n",
      "layer_dim: 50\n",
      "learning_rate: 0.0001\n",
      "max_grad_norm: 5.0\n",
      "fw_lambda: 0.9\n",
      "fw_eta: 0.5\n",
      "c_alpha: 40\n",
      "c_lambda: 0.01\n",
      "c_layer_norm: True\n",
      "init_scale: 0.1\n",
      "layer_norm: True\n",
      "norm_gain: 1\n",
      "norm_shift: 1\n",
      "optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x120270be0>\n",
      "fw_activation: <function tanh at 0x11a3031e0>\n",
      "clip_gradients: False\n"
     ]
    }
   ],
   "source": [
    "conf = Default_AR_Config()\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9. 9. 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "test = tf.constant(np.ones([5])*9)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res=sess.run(test)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9]],\n",
      "\n",
      "       [[12, 13, 14],\n",
      "        [15, 16, 17],\n",
      "        [18, 19, 20]]], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.util import nest\n",
    "inputs = tf.constant([[[1,2,3],[4,5,6],[7,8,9]],[[12,13,14,],[15,16,17],[18,19,20]]])\n",
    "flat_input = nest.flatten(inputs)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(flat_input)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[4.5,  6.5], [1.2, 7.1]])\n",
    "y = tf.constant([[4.5,  6.5], [1.2, 7.4]])\n",
    "res = tf.reduce_all(tf.equal(x,y))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    erg = sess.run(res)\n",
    "    print(erg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.41421356 1.41421356 1.41421356]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch = tf.constant(np.ones((3,2)))\n",
    "\n",
    "normalized = batch / tf.norm(batch,keepdims=True,axis=1)\n",
    "lengths = tf.norm(batch,keepdims=False,axis=1)\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(lengths)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 4)\n",
      "[[[24. 24. 24. 24.]]\n",
      "\n",
      " [[24. 24. 24. 24.]]\n",
      "\n",
      " [[24. 24. 24. 24.]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "batchsize = 3\n",
    "c = tf.constant(np.ones((batchsize,4,4))*2)\n",
    "state = tf.constant(np.ones((batchsize,1,4))*3)\n",
    "\n",
    "res = tf.matmul(state, c)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(res)\n",
    "    print(result.shape)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "images = map(Image.open, ['heatmap_autoconceptor_mnist28_1.png', 'heatmap_autoconceptor_mnist28_2.png'])\n",
    "widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "total_width = sum(widths)\n",
    "max_height = max(heights)\n",
    "\n",
    "new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "x_offset = 0\n",
    "for im in images:\n",
    "    new_im.paste(im, (x_offset,0))\n",
    "    x_offset += im.size[0]\n",
    "\n",
    "new_im.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_2:0\", shape=(5, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "test = tf.constant(np.ones([5,10,100])) #batchsize x sequence_length x output_dim\n",
    "ma = tf.argmax(test,axis=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(ma)\n",
    "    print(ma) # gewollt: batchsize x sequence_length, also 5x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 0 1 2 3 2 3 4 5 3 4 5 6 5 6 7 8 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "def construct_sequence_smart(data, sequence_length, batchsize):\n",
    "    \"\"\"\n",
    "    data = list of strings (the encoded words of the file)\n",
    "    batchsize = the size of the expected batches\n",
    "    \"\"\"\n",
    "    length = len(data)\n",
    "    chunk = batchsize * sequence_length\n",
    "    rep = int((length - (length % chunk))/chunk)\n",
    "    sequence_starts = np.arange(batchsize*rep)*sequence_length # [0,4,8,12,16,20]\n",
    "    indices = np.arange(len)\n",
    "    ordered_starts = sequence_starts[indices] # [0,8,16,4,12,20] indices: 0,2,4,1,3,5\n",
    "    indices_pre = np.repeat(np.arange(batchsize)*rep, rep) + np.repeat(np.arange(rep), batchsize)\n",
    "    \n",
    "    indices = np.repeat(indices_pre, sequence_length) + np.tile(np.arange(sequence_length), batchsize*rep)\n",
    "\n",
    "    new_data = data[[indices]]\n",
    "    return new_data\n",
    "\n",
    "print(construct_smart_sequence(np.arange(25),4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_sequence_iter(data, sequence_length, batchsize):\n",
    "    length = len(data)\n",
    "    chunk = batchsize * sequence_length\n",
    "    rep = int((length - (length % chunk))/chunk)\n",
    "    sequence_starts = np.arange(batchsize*rep)*sequence_length #clean_length /sequence_length\n",
    "    print(sequence_starts)#[0,4,8,12,16,20]\n",
    "    new_data = []\n",
    "    for add in range(rep):\n",
    "        i = 0\n",
    "        while(i < len(sequence_starts)):\n",
    "            s = sequence_starts[i+add]\n",
    "            new_data = new_data+data[s:s+sequence_length]\n",
    "            i += rep\n",
    "    return new_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n",
      "[ 0  4  8 12 16 20 24 28 32]\n",
      "[0, 1, 2, 3, 12, 13, 14, 15, 24, 25, 26, 27, 4, 5, 6, 7, 16, 17, 18, 19, 28, 29, 30, 31, 8, 9, 10, 11, 20, 21, 22, 23, 32, 33, 34, 35]\n"
     ]
    }
   ],
   "source": [
    "data = list(np.arange(0,37))\n",
    "print(data)\n",
    "new_data = construct_sequence_iter(data, 4, 3)\n",
    "#new_data_correct = [0,1,2,3,8,9,10,11,16,17,18,19,4,5,6,7,12,13,14,15,20,21,22,23]\n",
    "#print(new_data_correct)\n",
    "print(new_data)\n",
    "#assert new_data == new_data_correct,\"Assert failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = [346,23,10,985,19]\n",
    "b = [346,23,10,985,19]\n",
    "np.random.shuffle(b)\n",
    "print(a == b)\n",
    "print(set(a) == set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "testlist = [0,1,2,3,4,5]\n",
    "print(testlist[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 6, 7, -1, -1, -1]\n",
      "[0, 5, 6, 7, 4]\n"
     ]
    }
   ],
   "source": [
    "def pad(sentence,sequence_length):\n",
    "    length = len(sentence)\n",
    "    if(length>sequence_length):\n",
    "        return sentence[0:sequence_length]\n",
    "    if(length<sequence_length):\n",
    "        return sentence + [-1] * (sequence_length - length)\n",
    "    \n",
    "testlist= [0,5,6,7]\n",
    "testlist2=[0,5,6,7,4,3,6,7,9,6,3,5,7,4,3]\n",
    "print(pad(testlist,7))\n",
    "print(pad(testlist2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mask = tf.sequence_mask([4,5,1],10)\n",
    "to_float = tf.cast(mask,tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(to_float)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17 45 21 87]\n",
      " [21 11 21 17]\n",
      " [87 17 11 17]]\n"
     ]
    }
   ],
   "source": [
    "pred = tf.constant([[1,3,2,4],\n",
    "                   [2,0,2,1],\n",
    "                   [4,1,0,1]])\n",
    "\n",
    "frequencies = tf.constant([11,17,21,45,87])\n",
    "\n",
    "res = tf.gather(frequencies, pred)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    out = session.run(res)\n",
    "    print(out)# expecting ([17, 45, 21, 87] [21, 11, 21, 17] [87, 17, 11, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 3, 'this': 2, 'is': 2, 'test': 1, 'one': 1})\n",
      "9\n",
      "{'this': 0.2222222222222222, 'is': 0.2222222222222222, 'a': 0.3333333333333333, 'test': 0.1111111111111111, 'one': 0.1111111111111111}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "data = ['this', 'is', 'a', 'is', 'a','a','test','this', 'one']\n",
    "c = Counter(data)\n",
    "print(c)\n",
    "import numpy as np\n",
    "total = np.sum(list(c.values()))\n",
    "print(total)\n",
    "\n",
    "c_new = {k: v / total for total in (sum(c.values()),) for k, v in c.items()}\n",
    "print(c_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.asarray([[1,1,1],\n",
    "                   [2,2,2],\n",
    "                   [3,3,3]])\n",
    "\n",
    "roll, pitch, yaw = np.mean(data, 0)\n",
    "print(roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
